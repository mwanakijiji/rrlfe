{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135371e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This automates removal of cosmic rays from SDSS red and blue single-epoch spectra,\n",
    "# as required by Young Sun\n",
    "\n",
    "# Created 2022 Dec. 3 by E.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1072bd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOrder of operations:\\n\\n1.) Based on number of single-epoch spectra\\n    - If 1 spectrum only, ignore for now\\n    - If 2 spectra only, do a sigma-clipping and identify anomalies *upward* (with a window) \\n    - If >=3 spectra, find median spectrum and identify outliers (with a window) \\n2.) TBD\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Order of operations:\n",
    "\n",
    "1.) Based on number of single-epoch spectra\n",
    "    - If 1 spectrum only, ignore for now\n",
    "    - If 2 spectra only, do a sigma-clipping and identify anomalies *upward* (with a window) \n",
    "    - If >=3 spectra, find median spectrum and identify outliers (with a window) \n",
    "2.) TBD\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc68ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.stats import sigma_clip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cf6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find names of spectra for which continuum has been calculated\n",
    "\n",
    "# top-level directory for SDSS spectra cosmic ray removal\n",
    "stem_raw_single_epoch = \"/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/\"+\\\n",
    "                        \"01_separated_and_interpolated/\"\n",
    "\n",
    "# find individual file names\n",
    "file_list = glob.glob(stem_raw_single_epoch + \"*.csv\")\n",
    "# find all parent names (i.e., one name for each target, whether or not multiepoch observations were made)\n",
    "parent_list = list(set([i.split(\"_g0\")[0] for i in file_list]))\n",
    "\n",
    "# find individual file names\n",
    "file_list_red = glob.glob(stem_raw_single_epoch + \"*color_red.csv\")\n",
    "# find all parent names (i.e., one name for each target, whether or not multiepoch observations were made)\n",
    "parent_list_red = list(set([i.split(\"_g0\")[0] for i in file_list_red]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11eae75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_from_avg(df_empir_pass,df_avg_pass,df_median_pass,sigma_choice=1):\n",
    "    '''\n",
    "    Flag points based on their deviation from the average spectrum\n",
    "    \n",
    "    INPUTS:\n",
    "    df_empir_pass: dataframe of empirical spectrum\n",
    "    df_avg_pass: dataframe of average spectrum\n",
    "    df_median_pass: dataframe of median spectrum\n",
    "    sigma_choice: threshold for clipping\n",
    "    '''\n",
    "    \n",
    "    # initialize DataFrame to return\n",
    "    masked_spec = df_empir_pass.copy(deep=True)\n",
    "    #masked_spec[\"flux_masked_1\"] = masked_spec[\"flux\"]\n",
    "    \n",
    "    # take difference between empirical spectrum and the AVERAGE of the AVERAGE AND MEDIAN spectrum\n",
    "    # (note this preserves sign information, and (if only 2 spectra are being compared) protects against \n",
    "    # misidentification of a cosmic ray in 1 spectrum when the ray is actually in the other)\n",
    "    #initialize DataFrame for taking an average of some kind\n",
    "    standin_df = df_avg_pass.copy(deep=True)\n",
    "    standin_df[\"median_flux\"] = df_median_pass[\"median_flux\"]\n",
    "    # remove column of wavelengths\n",
    "    print(standin_df.keys())\n",
    "    standin_df = standin_df.drop(labels=[\"wavel\"],axis=1)\n",
    "    # find the mean of a mean and a median\n",
    "    standin_df[\"mean_of_stuff\"] = standin_df.mean(axis=1) # average of the columns\n",
    "    \n",
    "    #avg_flux = np.expand_dims(df_avg_pass[\"avg_flux\"].values,axis=1)\n",
    "    #median_flux = np.expand_dims(df_median_pass[\"median_flux\"].values,axis=1)\n",
    "    #print(np.expand_dims(avg_flux,axis=0).shape)\n",
    "    #print(median_flux.shape)\n",
    "    #mean_median_combo = np.mean(avg_flux,median_flux)\n",
    "    masked_spec[\"diff\"] = np.subtract(df_empir_pass[\"flux\"],standin_df[\"mean_of_stuff\"])\n",
    "    \n",
    "    plt.plot(masked_spec[\"diff\"])\n",
    "    plt.show()\n",
    "    \n",
    "    # mask deviant points\n",
    "    # logic: is difference in the array beyond error bounds?\n",
    "    error_bound = sigma_choice*np.nanstd(masked_spec[\"diff\"])\n",
    "    logic_1 = np.greater(masked_spec[\"diff\"],error_bound)\n",
    "    masked_spec[\"flux_flag_1\"] = logic_1 # flag these points as suspect\n",
    "    \n",
    "    return masked_spec, error_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6adfeb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## begin test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30de9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "\n",
    "matching_all = list(filter(lambda x: parent_list[t] in x, file_list))\n",
    "matching_red = list(filter(lambda x: \"color_red\" in x, matching_all))\n",
    "matching_blue = list(filter(lambda x: \"color_blue\" in x, matching_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec80ff1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matching' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c4b6b93e9f56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# intialize array to contain all fluxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"wavel\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"flux\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"noise\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maggregate_flux_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matching' is not defined"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "\n",
    "# intialize array to contain all fluxes\n",
    "df_dummy = pd.read_csv(matching[0], names=[\"wavel\",\"flux\",\"noise\"], delim_whitespace=False, skiprows=1)\n",
    "aggregate_flux_array = np.nan*np.ones((len(df_dummy),len(matching)))\n",
    "\n",
    "for p in range(0,10):\n",
    "    \n",
    "    print(p)\n",
    "    print(matching[p])\n",
    "\n",
    "    df_single_p = pd.read_csv(matching[p], names=[\"wavel\",\"flux\",\"noise\"], delim_whitespace=False, skiprows=1)\n",
    "\n",
    "    if p==0:\n",
    "        # for checking wavel abcissa is same\n",
    "        wavel_initial = df_single_p[\"wavel\"].values\n",
    "    else:\n",
    "        '''\n",
    "        print(df_single_p[\"wavel\"])\n",
    "        print(wavel_initial)\n",
    "        print(len(np.setdiff1d(df_single_p[\"wavel\"].values,wavel_initial)))\n",
    "        '''\n",
    "        \n",
    "        non_common = np.setdiff1d(df_single_p[\"wavel\"].values,wavel_initial)\n",
    "        \n",
    "        if len(non_common >= 1):\n",
    "            print(\"Hey, the wavelength abcissas are not the same!\")\n",
    "            print(non_common)\n",
    "            sys.exit()\n",
    "            \n",
    "    # put fluxes into array\n",
    "    aggregate_flux_array[:,p] = df_single_p[\"flux\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## end test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae1a7e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-0928-52578-0271_g001_color_red.csv', '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-0928-52578-0271_g002_color_red.csv', '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-0928-52578-0271_g000_color_red.csv']\n",
      "['/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-0928-52578-0271_g002_color_blue.csv', '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-0928-52578-0271_g000_color_blue.csv', '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-0928-52578-0271_g001_color_blue.csv']\n"
     ]
    }
   ],
   "source": [
    "# loop over each parent FITS file\n",
    "for t in range(0,1):#len(parent_list)):\n",
    "\n",
    "    matching_all = list(filter(lambda x: parent_list[t] in x, file_list))\n",
    "    matching_red = list(filter(lambda x: \"color_red\" in x, matching_all))\n",
    "    matching_blue = list(filter(lambda x: \"color_blue\" in x, matching_all))\n",
    "    \n",
    "    #print(matching_all)\n",
    "    #print(matching_red)\n",
    "    #print(matching_blue)\n",
    "    \n",
    "    # keep the red and blue parts separate\n",
    "    for color_num in range(0,2):\n",
    "        \n",
    "        if color_num==0:\n",
    "            matching = matching_red\n",
    "        elif color_num==1:\n",
    "            matching = matching_blue\n",
    "        print(matching)\n",
    "        ## ## CONTINUE HERE; GO THROUGH STEP BY STEP \n",
    "        \n",
    "        '''\n",
    "\n",
    "        print(\"-------------------------\")\n",
    "\n",
    "        if (len(matching) == 1):\n",
    "\n",
    "            print(\"Only one match found for this color:\")\n",
    "            print(matching)\n",
    "\n",
    "        elif (len(matching) >= 2):\n",
    "\n",
    "\n",
    "\n",
    "            # dictionary to hold dataframes\n",
    "            d = {}\n",
    "\n",
    "            # intialize array to contain all fluxes\n",
    "            df_dummy = pd.read_csv(matching[0], names=[\"wavel\",\"flux\",\"noise\"], delim_whitespace=False, skiprows=1)\n",
    "            aggregate_flux_array = np.nan*np.ones((len(df_dummy),len(matching)))\n",
    "\n",
    "            # collect spectra in single dictionary\n",
    "            for p in range(0,len(matching)):\n",
    "\n",
    "                df_single_p = pd.read_csv(matching[p], names=[\"wavel\",\"flux\",\"noise\"], delim_whitespace=False, skiprows=1)\n",
    "\n",
    "                #plt.plot(df_single_p[\"wavel\"],df_single_p[\"flux\"])\n",
    "\n",
    "                # sanity check that wavelength abcissa are the same\n",
    "                if p==0:\n",
    "                    # for checking wavel abcissa is same\n",
    "                    wavel_initial = df_single_p[\"wavel\"].values\n",
    "                else:\n",
    "                    print(df_single_p[\"wavel\"])\n",
    "                    print(wavel_initial)\n",
    "                    print(len(np.setdiff1d(df_single_p[\"wavel\"].values,wavel_initial)))\n",
    "                    if len(np.setdiff1d(df_single_p[\"wavel\"].values,wavel_initial) >= 1):\n",
    "                        print(\"Hey, the wavelength abcissas are not the same!\")\n",
    "                        sys.exit()\n",
    "\n",
    "                # put fluxes into array\n",
    "                aggregate_flux_array[:,p] = df_single_p[\"flux\"].values\n",
    "\n",
    "            # take mean flux of all the spectra\n",
    "            mean_flux_array = np.mean(aggregate_flux_array,axis=1)\n",
    "\n",
    "            # cast mean spectrum data as DataFrame\n",
    "            df_mean = pd.DataFrame(mean_flux_array,columns=[\"avg_flux\"])\n",
    "            df_mean[\"wavel\"] = df_single_p[\"wavel\"] # uses last spectrum read in\n",
    "            # include median flux too (important for identifying cosmic rays when only 2 spectra are compared)\n",
    "            median_flux_array = np.median(aggregate_flux_array,axis=1)\n",
    "            print(median_flux_array)\n",
    "            df_median = pd.DataFrame(median_flux_array,columns=[\"median_flux\"])\n",
    "            df_median[\"wavel\"] = df_single_p[\"wavel\"] # uses last spectrum read in\n",
    "            #mean_flux_array[\"median_flux\"] = pd.Series(median_flux_array.tolist())\n",
    "\n",
    "            for p in range(0,len(matching)):\n",
    "                # test each empirical spectrum against the mean, and flag points\n",
    "                df_single_p = pd.read_csv(matching[p], names=[\"wavel\",\"flux\",\"noise\"], delim_whitespace=True)\n",
    "                flagged_empirical, limit = flag_from_avg(\n",
    "                                                        df_empir_pass = df_single_p,\n",
    "                                                        df_avg_pass = df_mean,\n",
    "                                                        df_median_pass = df_median,\n",
    "                                                        sigma_choice=5\n",
    "                                                        )\n",
    "\n",
    "                # if cosmic ray appears to be in an absorption line, discard the spectrum\n",
    "                ## ## TBD\n",
    "\n",
    "\n",
    "                #plt.plot(wavel_initial,mean_flux_array,linestyle=\"--\",color=\"k\")\n",
    "                #plt.show()\n",
    "                #plt.clf()\n",
    "\n",
    "                fig = plt.figure(figsize=(24,10))\n",
    "                plt.plot(flagged_empirical[\"wavel\"],np.subtract(flagged_empirical[\"flux_flag_1\"],1),color=\"gray\",alpha=1)\n",
    "                #.axvline(x=0, ymin=0, ymax=1\n",
    "                plt.plot(flagged_empirical[\"wavel\"],flagged_empirical[\"diff\"],label=\"diff\")\n",
    "                plt.plot(df_mean[\"wavel\"],np.add(df_mean[\"avg_flux\"],0.2),label=\"mean\")\n",
    "                plt.plot(flagged_empirical[\"wavel\"],flagged_empirical[\"flux\"],label=\"empirical\")\n",
    "                #plt.plot(df_single_p[\"wavel\"].where(test[\"flux_flag_1\"] == True),\n",
    "                #             df_single_p[\"flux\"].where(test[\"flux_flag_1\"] == True),\n",
    "                #         label=\"flagged\",color=\"k\",linewidth=4)\n",
    "                plt.plot([3900,5000],[limit,limit],linestyle=\"--\")\n",
    "                plt.title(str(os.path.basename(matching[p])))\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig(\"plot_\" + str(os.path.basename(matching[p])) + \".png\",\n",
    "                            facecolor=\"white\", edgecolor='white')\n",
    "                plt.clf()\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2abfd6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g001_color_blue.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g003_color_red.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g004_color_red.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g000_color_red.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g000_color_blue.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g002_color_blue.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g004_color_blue.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g003_color_blue.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g001_color_red.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g002_color_red.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"color_red\" in matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d4df899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g003_color_red.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g004_color_red.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g000_color_red.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g001_color_red.csv',\n",
       " '/Users/bandari/Documents/git.repos/rrlfe/notebooks_for_development/sdss_processing/01_separated_and_interpolated/spec-3005-54876-0348_g002_color_red.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_red = list(filter(lambda x: \"color_red\" in x, matching))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243e8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
